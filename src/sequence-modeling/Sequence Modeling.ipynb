{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_glove_file = r\"/Users/anshuman/UMass/CS 682/Project/glove.6B/glove.6b.300d.txt\" ## glove text file that you download from internet, 6b words 300d,\n",
    "new_glove_file =r\"glove6b300d.bin\"\n",
    "movie_data_file =r\"ml-1m/movies.dat\" #movie data file\n",
    "user_data_file =r\"ml-1m/users.dat\" #user data file\n",
    "rating_data_file = r\"ml-1m/ratings.dat\" #rating data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run this only once ever, if you have skip this and go to the next cell\n",
    "## Insert your glove location below.\n",
    "## This is done to convert .txt glove to binary format for easier loading.\n",
    "glove_file = datapath(og_glove_file)\n",
    "tmp_file = get_tmpfile(\"glove.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "model.save_word2vec_format(new_glove_file,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshuman/anaconda3/envs/cs682/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    " ##load binary glove model\n",
    "glove_model = gensim.models.KeyedVectors.load_word2vec_format(new_glove_file,binary=True)\n",
    "##get vocabulary\n",
    "vocab = list(glove_model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the dataset into dataframes\n",
    "\n",
    "movieData = pd.read_csv(movie_data_file,sep=\"::\",names=[\"MovieID\",\"Name\",\"Genres\"],engine='python')\n",
    "userData = pd.read_csv(user_data_file,sep=\"::\",names=[\"UserID\",\"Gender\",\"Age\",\"Occupation\",\"Zipcode\"],engine='python')\n",
    "ratingData = pd.read_csv(rating_data_file,sep=\"::\",names=[\"UserID\",\"MovieID\",\"Rating\",\"Timestamp\"],engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## movie data preprocessing  - getting a dictionary of movie name and id pairs,\n",
    "##creating genrelist, and reseting movieData dataframe\n",
    "\n",
    "movieNameData = movieData[\"Name\"].unique()\n",
    "movieNameDict = {movieNameData[i]:i for i in range(0,movieNameData.shape[0])}\n",
    "genreList = [\"Action\",\"Adventure\",\"Animation\",\"Children's\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\n",
    "              \"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\"]\n",
    "genres = movieData[\"Genres\"].apply(lambda x : x.split(\"|\"))\n",
    "movieData.reset_index(inplace=True,drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3883, 3)\n",
      "Movie Embeddings (3953, 318)\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import MovieEncodingEmbedding\n",
    "\n",
    "print(movieData.shape)\n",
    "numRows = movieData.shape[0]\n",
    "# print(movieData, movieData.loc[0][0], movieData.loc[0][1], movieData.loc[0][2])\n",
    "movie_embeddings = np.zeros((3953, 318))\n",
    "\n",
    "# Prepare movie embeddings -> A Mapping from MovieID to its embedding. This can then be used during model training\n",
    "for rowNum in range(numRows):\n",
    "    movieID = movieData.loc[rowNum]['MovieID']\n",
    "#     print(rowNum, movieID)\n",
    "    movie_embeddings[movieID] = MovieEncodingEmbedding(movieID, movieData, genreList, glove_model, vocab)\n",
    "\n",
    "print(\"Movie Embeddings\", movie_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import UserSequences\n",
    "\n",
    "## get user Sequences\n",
    "userSequences = UserSequences(ratingData,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5421\n",
      "27\n",
      "(3873,)\n"
     ]
    }
   ],
   "source": [
    "print(len(userSequences))\n",
    "print(len(userSequences[0]))\n",
    "print(userSequences[99][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get user-movie encodings for the data with embedding flag false and write it to file.\n",
    "## In every file each line will contain\n",
    "##userid::gender::userDataAge::userDataOccupation::userDataZipCode::movieid::(one hot genre encoding of len 18[each separated by ::]):rating \n",
    "# data = UserMoviePairEncodingBatch(userSequences,False)\n",
    "\n",
    "# with open(\"usermovie.dat\",\"w\") as f:\n",
    "#     for i in range(len(data)):\n",
    "#         for j in range(data[i].shape[0]):\n",
    "#             f.write(\"::\".join(data[i][j]))\n",
    "#             f.write(\"\\n\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get user-movie encodings for the data with embedding flag false and write it to file.\n",
    "## In every file each line will contain\n",
    "##userid::gender::userDataAge::userDataOccupation::userDataZipCode::(movieid_embedding[len 300, separated by ::])::(one hot genre encoding of len 18[each separated by ::]):rating \n",
    "\n",
    "# data = UserMoviePairEncodingBatch(userSequences,True)\n",
    "\n",
    "# with open(\"usermoviembeddings.dat\",\"w\") as f:\n",
    "#     for i in range(len(data)):\n",
    "#         for j in range(data[i].shape[0]):\n",
    "#             f.write(\"::\".join(data[i][j]))\n",
    "#             f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (3468, 27) (3468, 26, 318) (3468, 26)\n",
      "val (868, 27) (868, 26, 318) (868, 26)\n",
      "test (1085, 27) (1085, 26, 318) (1085, 26)\n"
     ]
    }
   ],
   "source": [
    "# np.array(data).shape\n",
    "# print (\"data\", len(data), data[0].shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fix(data):\n",
    "    newData = np.empty(data.shape, dtype=int)\n",
    "    for i, userSeq in enumerate(data):\n",
    "        for j, tup in enumerate(userSeq):\n",
    "            newData[i][j] = tup[0]\n",
    "    return newData\n",
    "\n",
    "data = fix(np.array(userSequences))\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "train_inp = movie_embeddings[train_data[:, :-1]]\n",
    "train_tgt = train_data[:, 1:]\n",
    "\n",
    "test_inp = movie_embeddings[test_data[:, :-1]]\n",
    "test_tgt = test_data[:, 1:]\n",
    "\n",
    "val_inp = movie_embeddings[val_data[:, :-1]]\n",
    "val_tgt = val_data[:, 1:]\n",
    "\n",
    "print (\"train\", train_data.shape, train_inp.shape, train_tgt.shape)\n",
    "print (\"val\", val_data.shape, val_inp.shape, val_tgt.shape)\n",
    "print (\"test\", test_data.shape, test_inp.shape, test_tgt.shape)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train torch.Size([3468, 26, 318]) torch.Size([3468, 26])\n",
      "Val torch.Size([868, 26, 318]) torch.Size([868, 26])\n",
      "Test torch.Size([1085, 26, 318]) torch.Size([1085, 26])\n"
     ]
    }
   ],
   "source": [
    "# train_data = batchify(torch.Tensor(train_data), 10)\n",
    "# val_data = batchify(torch.Tensor(val_data), 10)\n",
    "# test_data = batchify(torch.Tensor(test_data), 10)\n",
    "\n",
    "train_data_final = torch.Tensor(train_inp)\n",
    "val_data_final = torch.Tensor(val_inp)\n",
    "test_data_final = torch.Tensor(test_inp)\n",
    "\n",
    "train_tgt_final = torch.Tensor(train_tgt).long()\n",
    "val_tgt_final = torch.Tensor(val_tgt).long()\n",
    "test_tgt_final = torch.Tensor(test_tgt).long()\n",
    "\n",
    "print(\"Train\", train_data_final.shape, train_tgt_final.shape)\n",
    "print(\"Val\", val_data_final.shape, val_tgt_final.shape)\n",
    "print(\"Test\", test_data_final.shape, test_tgt_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |\n",
      "   20/   70 batches  | loss  7.67\n",
      "   40/   70 batches  | loss  7.49\n",
      "   60/   70 batches  | loss  7.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  8.72s | val loss  7.06 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |\n",
      "   20/   70 batches  | loss  7.12\n",
      "   40/   70 batches  | loss  7.11\n",
      "   60/   70 batches  | loss  7.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  8.70s | val loss  7.01 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |\n",
      "   20/   70 batches  | loss  7.06\n",
      "   40/   70 batches  | loss  7.06\n",
      "   60/   70 batches  | loss  7.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  8.73s | val loss  7.01 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |\n",
      "   20/   70 batches  | loss  7.04\n",
      "   40/   70 batches  | loss  7.04\n",
      "   60/   70 batches  | loss  7.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  8.89s | val loss  7.00 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |\n",
      "   20/   70 batches  | loss  7.03\n",
      "   40/   70 batches  | loss  7.03\n",
      "   60/   70 batches  | loss  7.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  8.85s | val loss  6.98 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |\n",
      "   20/   70 batches  | loss  7.02\n",
      "   40/   70 batches  | loss  7.02\n",
      "   60/   70 batches  | loss  7.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  9.04s | val loss  6.98 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |\n",
      "   20/   70 batches  | loss  7.00\n",
      "   40/   70 batches  | loss  7.01\n",
      "   60/   70 batches  | loss  7.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  9.05s | val loss  6.98 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |\n",
      "   20/   70 batches  | loss  7.00\n",
      "   40/   70 batches  | loss  7.00\n",
      "   60/   70 batches  | loss  7.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  9.09s | val loss  6.98 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |\n",
      "   20/   70 batches  | loss  6.99\n",
      "   40/   70 batches  | loss  7.00\n",
      "   60/   70 batches  | loss  7.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  9.26s | val loss  6.98 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |\n",
      "   20/   70 batches  | loss  6.99\n",
      "   40/   70 batches  | loss  6.99\n",
      "   60/   70 batches  | loss  7.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  9.45s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |\n",
      "   20/   70 batches  | loss  6.98\n",
      "   40/   70 batches  | loss  6.99\n",
      "   60/   70 batches  | loss  7.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  9.19s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |\n",
      "   20/   70 batches  | loss  6.98\n",
      "   40/   70 batches  | loss  6.98\n",
      "   60/   70 batches  | loss  6.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  9.16s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |\n",
      "   20/   70 batches  | loss  6.97\n",
      "   40/   70 batches  | loss  6.98\n",
      "   60/   70 batches  | loss  6.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  9.07s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |\n",
      "   20/   70 batches  | loss  6.97\n",
      "   40/   70 batches  | loss  6.97\n",
      "   60/   70 batches  | loss  6.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  9.16s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |\n",
      "   20/   70 batches  | loss  6.96\n",
      "   40/   70 batches  | loss  6.97\n",
      "   60/   70 batches  | loss  6.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  9.08s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |\n",
      "   20/   70 batches  | loss  6.96\n",
      "   40/   70 batches  | loss  6.97\n",
      "   60/   70 batches  | loss  6.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  9.01s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |\n",
      "   20/   70 batches  | loss  6.96\n",
      "   40/   70 batches  | loss  6.97\n",
      "   60/   70 batches  | loss  6.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  8.98s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |\n",
      "   20/   70 batches  | loss  6.95\n",
      "   40/   70 batches  | loss  6.96\n",
      "   60/   70 batches  | loss  6.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  8.95s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |\n",
      "   20/   70 batches  | loss  6.95\n",
      "   40/   70 batches  | loss  6.96\n",
      "   60/   70 batches  | loss  6.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  8.89s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |\n",
      "   20/   70 batches  | loss  6.95\n",
      "   40/   70 batches  | loss  6.96\n",
      "   60/   70 batches  | loss  6.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  8.88s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |\n",
      "   20/   70 batches  | loss  6.95\n",
      "   40/   70 batches  | loss  6.95\n",
      "   60/   70 batches  | loss  6.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  8.95s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |\n",
      "   20/   70 batches  | loss  6.94\n",
      "   40/   70 batches  | loss  6.95\n",
      "   60/   70 batches  | loss  6.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  8.89s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |\n",
      "   20/   70 batches  | loss  6.94\n",
      "   40/   70 batches  | loss  6.95\n",
      "   60/   70 batches  | loss  6.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  8.99s | val loss  6.98 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |\n",
      "   20/   70 batches  | loss  6.94\n",
      "   40/   70 batches  | loss  6.94\n",
      "   60/   70 batches  | loss  6.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  8.87s | val loss  6.97 \n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20/   70 batches  | loss  6.93\n",
      "   40/   70 batches  | loss  6.94\n",
      "   60/   70 batches  | loss  6.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  8.96s | val loss  6.98 \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from model import RNNModel\n",
    "from learner import Learner\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "_, temporal_batch_size, input_size = train_data_final.shape\n",
    "ntokens = 3953\n",
    "nlayers = 2\n",
    "hidden_size = 100\n",
    "dropout = 0.7\n",
    "train_batch_size = 50\n",
    "val_batch_size = val_data_final.shape[0]\n",
    "test_batch_size = test_data_final.shape[0]\n",
    "\n",
    "model = RNNModel('gru', ntokens, input_size, hidden_size, nlayers, dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=5)\n",
    "optimizer = optim.SGD(model.parameters(), lr=10)\n",
    "learner = Learner(model, criterion, optimizer)\n",
    "\n",
    "best_val_loss = None\n",
    "num_epochs = 25\n",
    "\n",
    "# Loop over epochs.\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print (\"| epoch {:3d} |\".format(epoch))\n",
    "    epoch_start_time = time.time()\n",
    "    learner.train(train_data_final, train_tgt_final, ntokens, train_batch_size)\n",
    "    val_loss = learner.evaluate(val_data_final, val_tgt_final, ntokens, val_batch_size)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | val loss {:5.2f} '\n",
    "          .format(epoch, (time.time() - epoch_start_time),\n",
    "                                       val_loss))\n",
    "    print('-' * 89)\n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        with open(\"model.pt\", 'wb') as f:\n",
    "            torch.save(model.state_dict(), f)\n",
    "        best_val_loss = val_loss\n",
    "#     else if lr > 1e-3:\n",
    "        # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "#         lr /= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plotLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel('gru', ntokens, input_size, hidden_size, nlayers, dropout)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "model.eval()\n",
    "generator = Learner(model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence:\n",
      "      MovieID                                           Name  \\\n",
      "2931     3000  Princess Mononoke, The (Mononoke Hime) (1997)   \n",
      "\n",
      "                          Genres  \n",
      "2931  Action|Adventure|Animation  \n",
      "      MovieID                Name                  Genres\n",
      "2502     2571  Matrix, The (1999)  Action|Sci-Fi|Thriller\n",
      "      MovieID                     Name  Genres\n",
      "3878     3948  Meet the Parents (2000)  Comedy\n",
      "    MovieID           Name          Genres\n",
      "15       16  Casino (1995)  Drama|Thriller\n",
      "     MovieID                           Name             Genres\n",
      "770      780  Independence Day (ID4) (1996)  Action|Sci-Fi|War\n",
      "      MovieID                             Name    Genres\n",
      "1229     1249  Nikita (La Femme Nikita) (1990)  Thriller\n",
      "      MovieID                         Name            Genres\n",
      "1214     1233  Boat, The (Das Boot) (1981)  Action|Drama|War\n",
      "    MovieID                  Name  Genres\n",
      "99      101  Bottle Rocket (1996)  Comedy\n",
      "     MovieID            Name        Genres\n",
      "232      235  Ed Wood (1994)  Comedy|Drama\n",
      "      MovieID                               Name      Genres\n",
      "2333     2402  Rambo: First Blood Part II (1985)  Action|War\n",
      "      MovieID                       Name                          Genres\n",
      "2399     2468  Jumpin' Jack Flash (1986)  Action|Comedy|Romance|Thriller\n"
     ]
    }
   ],
   "source": [
    "generated_seq = learner.generate_seq (3000, movie_embeddings, 10)\n",
    "print(\"Generated Sequence:\")\n",
    "for id in generated_seq:\n",
    "    print(movieData.loc[movieData[\"MovieID\"]==id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  6.996011734008789\n"
     ]
    }
   ],
   "source": [
    "test_loss = learner.evaluate(test_data_final, test_tgt_final, ntokens, test_batch_size)\n",
    "print(\"Test Loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
