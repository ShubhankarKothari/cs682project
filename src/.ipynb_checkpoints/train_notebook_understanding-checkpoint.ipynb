{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMFEngine\n",
    "from mlp import MLPEngine\n",
    "from neumf import NeuMFEngine\n",
    "from data import SampleGenerator\n",
    "import utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_config = {'alias': 'gmf_factor8neg4-implict',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 1024,\n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "              # 'optimizer': 'rmsprop',\n",
    "              # 'rmsprop_lr': 1e-3,\n",
    "              # 'rmsprop_alpha': 0.99,\n",
    "              # 'rmsprop_momentum': 0,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'l2_regularization': 0.001, # 0.01\n",
    "              'use_cuda': False,\n",
    "              'device_id': 0,\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 256,  # 1024,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "              'use_cuda': False,\n",
    "              'device_id': 7,\n",
    "              'pretrain': True,\n",
    "              'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 200,\n",
    "                'batch_size': 1024,\n",
    "                'optimizer': 'adam',\n",
    "                'adam_lr': 1e-3,\n",
    "                'num_users': 6040,\n",
    "                'num_items': 3706,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'num_negative': 4,\n",
    "                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'l2_regularization': 0.01,\n",
    "                'use_cuda': True,\n",
    "                'device_id': 7,\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "                'pretrain_mlp': 'checkpoints/{}'.format('mlp_factor8neg4_Epoch100_HR0.5606_NDCG0.2463.model'),\n",
    "                'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of userId is [0, 5420]\n",
      "Range of itemId is [0, 3350]\n",
      "    userId  itemId  rating  timestamp  rank_latest\n",
      "0        0       0       1  978300019         27.0\n",
      "1        0       1       1  978300055         24.0\n",
      "2        0       2       1  978300055         25.0\n",
      "3        0       3       1  978300055         26.0\n",
      "4        0       4       1  978300103         23.0\n",
      "5        0       5       1  978300172         22.0\n",
      "6        0       6       1  978300275         21.0\n",
      "7        0       7       1  978300719         19.0\n",
      "8        0       8       1  978300719         20.0\n",
      "9        0       9       1  978300760         16.0\n",
      "10       0      10       1  978300760         17.0\n",
      "11       0      11       1  978300760         18.0\n",
      "12       0      12       1  978301368         15.0\n",
      "13       0      13       1  978301398         14.0\n",
      "14       0      14       1  978301570         13.0\n",
      "15       0      15       1  978301590         12.0\n",
      "16       0      16       1  978301619         11.0\n",
      "17       0      17       1  978301713         10.0\n",
      "18       0      18       1  978301752          9.0\n",
      "19       0      19       1  978301753          7.0\n",
      "20       0      20       1  978301753          8.0\n",
      "21       0      21       1  978301777          4.0\n",
      "22       0      22       1  978301777          5.0\n",
      "23       0      23       1  978301777          6.0\n",
      "24       0      24       1  978301953          3.0\n",
      "25       0      25       1  978301968          2.0\n",
      "26       0      26       1  978302039          1.0\n",
      "27       1      27       1  978298124         27.0\n",
      "28       1      28       1  978298151         25.0\n",
      "29       1      29       1  978298151         26.0\n",
      "   userId  itemId  rating                                   negative_samples\n",
      "0       0      21       1  [1604, 3131, 1749, 192, 1087, 2121, 2017, 1685...\n",
      "1       0      22       1  [1604, 3131, 1749, 192, 1087, 2121, 2017, 1685...\n",
      "2       0      24       1  [1604, 3131, 1749, 192, 1087, 2121, 2017, 1685...\n",
      "3       0      25       1  [1604, 3131, 1749, 192, 1087, 2121, 2017, 1685...\n",
      "4       0      26       1  [1604, 3131, 1749, 192, 1087, 2121, 2017, 1685...\n",
      "(27105, 4)\n",
      "(2710500, 4)\n",
      "(2710500, 4)\n",
      "5421\n",
      "[Evluating Epoch 0] HR = 0.0918, NDCG = 0.4534\n"
     ]
    }
   ],
   "source": [
    "ml1m_dir = 'data/ml-1m/ratingTraining.dat'\n",
    "ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "# Reindex\n",
    "ml1m_uwf = 'data/ml-1m/unwatchedFilms.dat'\n",
    "uwflist = []\n",
    "with open(ml1m_uwf) as f: uwflist =[int(i[:-1]) for i in f.readlines()]        \n",
    "user_id = ml1m_rating[['uid']].drop_duplicates().reindex()\n",
    "user_id['userId'] = np.arange(len(user_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, user_id, on=['uid'], how='left')\n",
    "item_id = ml1m_rating[['mid']].drop_duplicates()\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, item_id, on=['mid'], how='left')\n",
    "ml1m_rating = ml1m_rating[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "print('Range of userId is [{}, {}]'.format(ml1m_rating.userId.min(), ml1m_rating.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(ml1m_rating.itemId.min(), ml1m_rating.itemId.max()))\n",
    "# DataLoader for training\n",
    "sample_generator = SampleGenerator(ratings=ml1m_rating,uwf_list=uwflist)\n",
    "evaluate_data = sample_generator.evaluate_data\n",
    "# Specify the exact model\n",
    "config = gmf_config\n",
    "engine = GMFEngine(config)\n",
    "state_dict = torch.load( 'checkpoints/gmf_factor8neg4-implict_Epoch199_HR0.6363_NDCG0.3678.model')\n",
    "engine.model.load_state_dict(state_dict)\n",
    "\n",
    "#utils.resume_checkpoint(engine.model, 'checkpoints/gmf_factor8neg4-implict_Epoch199_HR0.6363_NDCG0.3678.model', config['device_id'])\n",
    "#engine.model = torch.load('checkpoints/gmf_factor8neg4-implict_Epoch199_HR0.6363_NDCG0.3678.model')\n",
    "hit_ratio, ndcg = engine.evaluate(evaluate_data, epoch_id=0)\n",
    "engine.save(config['alias'], 0, hit_ratio, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2710500/5421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2710500, 3)\n",
      "(2710500, 3)\n",
      "5421\n"
     ]
    }
   ],
   "source": [
    "from metrics import MetronAtK\n",
    "_metron = MetronAtK(top_k=10)\n",
    "engine.model.eval()\n",
    "with torch.no_grad():\n",
    "    test_users, test_items = evaluate_data[0], evaluate_data[1]\n",
    "    negative_users, negative_items = evaluate_data[2], evaluate_data[3]\n",
    "    test_scores = engine.model(test_users, test_items)\n",
    "    negative_scores = engine.model(negative_users, negative_items)\n",
    "    _metron.subjects = [test_users.data.view(-1).tolist(),\n",
    "                                 test_items.data.view(-1).tolist(),\n",
    "                                 test_scores.data.view(-1).tolist(),\n",
    "                                 negative_users.data.view(-1).tolist(),\n",
    "                                 negative_items.data.view(-1).tolist(),\n",
    "                                 negative_scores.data.view(-1).tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user  item     score  rank\n",
      "2683399     0    26  0.955286   1.0\n",
      "2683396     0    22  0.954951   2.0\n",
      "51          0    84  0.784121   3.0\n",
      "77          0   400  0.749840   4.0\n",
      "2683398     0    25  0.731213   5.0\n",
      "87          0   538  0.718056   6.0\n",
      "16          0  1181  0.543746   7.0\n",
      "2683395     0    21  0.456222   8.0\n",
      "19          0   415  0.440439   9.0\n",
      "15          0   597  0.402159  10.0\n",
      "572         1   136  0.899110   1.0\n",
      "584         1   115  0.825122   2.0\n",
      "548         1    93  0.756404   3.0\n",
      "531         1  1154  0.714274   4.0\n",
      "575         1   799  0.685619   5.0\n",
      "2683401     1    47  0.629828   6.0\n",
      "547         1  1022  0.568471   7.0\n",
      "507         1  1092  0.567496   8.0\n",
      "504         1   162  0.541935   9.0\n",
      "588         1   534  0.527291  10.0\n",
      "1024        2   264  0.881943   1.0\n",
      "1058        2   214  0.873100   2.0\n",
      "1005        2   277  0.828644   3.0\n",
      "2683406     2    68  0.694055   4.0\n",
      "1013        2   843  0.685498   5.0\n",
      "1036        2   743  0.645211   6.0\n",
      "991         2   120  0.641035   7.0\n",
      "1027        2   675  0.615635   8.0\n",
      "2683405     2    67  0.611739   9.0\n",
      "1008        2   188  0.608861  10.0\n",
      "(54210, 4)\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "full,top_k = _metron._subjects,_metron._top_k\n",
    "top_k = full[full['rank']<=top_k]\n",
    "score = 0.0\n",
    "print(top_k.iloc[:30])\n",
    "print(top_k.shape)\n",
    "_test_items = { d['user'].iloc[0]:d['item'].to_list() for i,d in top_k.groupby('user')}\n",
    "score = sum([sum(d[d['item'].isin(_test_items[d['user'].iloc[0]])]['rank'].apply(lambda x: math.log(2) / math.log(1 + x)).to_list()) for i,d in top_k.groupby('user')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24630.635171778773"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'uwf_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c3a339a355c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSampleGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mml1m_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Specify the exact model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmf_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGMFEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'uwf_list'"
     ]
    }
   ],
   "source": [
    "sample_generator = SampleGenerator(ratings=ml1m_rating)\n",
    "evaluate_data = sample_generator.evaluate_data\n",
    "# Specify the exact model\n",
    "config = gmf_config\n",
    "engine = GMFEngine(config)\n",
    "# config = mlp_config\n",
    "# engine = MLPEngine(config)\n",
    "# config = neumf_config\n",
    "# engine = NeuMFEngine(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1 = {d['user']:len(d[(d['item'].isin(self._test_items[d['user'].iloc[0]]))& (d['ratings']==1.0)]) for i,d in top_k.groupby('user')]\n",
    "score_2 = {d['user']:len(d[(d['item'].isin(self._test_items[d['user'].iloc[0]]))& (d['ratings']==0.0)]) for i,d in top_k.groupby('user')]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
